# Sentimental Analysis

import nltk                                # Python library for NLP
from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK
import matplotlib.pyplot as plt            # library for visualization
import random                              # pseudo-random number generator

# downloads sample twitter dataset.
nltk.download('twitter_samples')

# We can load the text fields of the positive and negative tweets by using the module's strings() method like this:
# select the set of positive and negative tweets
all_positive_tweets = twitter_samples.strings('positive_tweets.json')
all_negative_tweets = twitter_samples.strings('negative_tweets.json')

# Next, we'll print a report with the number of positive and negative tweets. It is also essential to know the data structure of the datasets
print('Number of positive tweets: ', len(all_positive_tweets))
print('Number of negative tweets: ', len(all_negative_tweets))

print('\nThe type of all_positive_tweets is: ', type(all_positive_tweets))
print('The type of a tweet entry is: ', type(all_negative_tweets[0]))

fig = plt.figure(figsize=(5, 5))                                  # Declare a figure with a custom size
labels = 'Positives', 'Negative'                                  # labels for the two classes
sizes = [len(all_positive_tweets), len(all_negative_tweets)]      # Sizes for each slide

# Declare pie chart, where the slices will be ordered and plotted counter-clockwise:
plt.pie(sizes, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)

plt.axis('equal')                                                 # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()                                                        # Display the chart

## Looking at raw texts
print('\033[92m' + all_positive_tweets[random.randint(0,5000)])   # print positive in greeen
print('\033[91m' + all_negative_tweets[random.randint(0,5000)])   # print negative in red

## Preprocess raw text for Sentiment analysis
Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:
-Tokenizing the string
-Lowercasing
-Removing stop words and punctuation
-Stemming

# Our selected sample. Complex enough to exemplify each step
tweet = all_positive_tweets[2277]
print(tweet)
